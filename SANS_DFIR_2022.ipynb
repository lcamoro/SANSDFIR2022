{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SANS DFIR 2022.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1n64o_dj9zdHtyGSoW172Sl0HUYZdSa1t",
      "authorship_tag": "ABX9TyP31dataAPnGPoAxCw4R595"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Main Libraries"
      ],
      "metadata": {
        "id": "wp720pFQ-oNh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_vHgEm3-Hey"
      },
      "outputs": [],
      "source": [
        "# Install Libraries\n",
        "!pip install psycopg2\n",
        "!pip install psycopg2-binary\n",
        "!pip install OTXv2\n",
        "!pip install import-ipynb\n",
        "!pip install haversine\n",
        "!pip install geoip2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load libraries"
      ],
      "metadata": {
        "id": "EMuK4W9p_JqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "import psycopg2\n",
        "from OTXv2 import OTXv2, IndicatorTypes\n",
        "import requests as req\n",
        "import pandas as pd\n",
        "from pandas import json_normalize\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "from bson import json_util, ObjectId\n",
        "import geoip2.database\n",
        "import haversine as hs\n",
        "from ipaddress import ip_address"
      ],
      "metadata": {
        "id": "DxaPHY5Q-sfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PostgreSQL Connection Constants"
      ],
      "metadata": {
        "id": "Svan-yzPE64b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pgUser = \"\"\n",
        "pgPass = \"\"\n",
        "pgHost = \"\"\n",
        "pgDB = \"\"\n",
        "pgPort = \"\""
      ],
      "metadata": {
        "id": "apay3F5kE5n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "jzl1j_GDANAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getConnData(pgUser, pgPass, pgHost, pgDB, pgPort):\n",
        "\tqryConnData = '''\n",
        "  SELECT \tc.creation_date, \n",
        "      c.public_ip, \n",
        "      c.country_id, \n",
        "      u.email\n",
        "  FROM connections.connections c\n",
        "  INNER JOIN connections.users u\n",
        "    ON u.user_id = c.user_id\n",
        "    '''\n",
        "\tpgConn = psycopg2.connect(database=pgDB, user=pgUser, password=pgPass, host=pgHost, port=pgPort)\n",
        "\tcur = pgConn.cursor()\n",
        "\tcur.execute(qryConnData)\n",
        "\trows = cur.fetchall()\n",
        "\t\n",
        "\tdfConnData = pd.DataFrame(rows, columns=[\"creation_date\", \"public_ip\", \"country_id\", \"email\"])\n",
        "\t\n",
        "\treturn dfConnData\n",
        "\n",
        "\n",
        "def getGeoData(ip, geoIPList):\n",
        "\tif ip_address(ip).is_private:\n",
        "\t\tgeoData = { \"geo_ip\":ip,\n",
        "\t\t\t    \"geo_country_name\":\"PRIVATE IP\",\n",
        "\t\t\t    \"geo_subdivisions\":\"\", \n",
        "\t\t\t    \"geo_city_name\":\"\",\n",
        "\t\t\t    \"geo_lat\":0.0,\n",
        "\t\t\t    \"geo_lon\":0.0,\n",
        "\t\t\t    \"geo_iso_code\":\"\",\n",
        "\t\t\t    \"geo_postal_code\":\"\"}\n",
        "\t\n",
        "\telse:\n",
        "\t\tgeodb_reader = geoip2.database.Reader('/content/drive/MyDrive/SANS_DFIR_2022/GeoLite2-City.mmdb')\n",
        "\t\tgeoResponse = geodb_reader.city(ip)\n",
        "\t\n",
        "\t\tgeoData = { \"geo_ip\":ip,\n",
        "\t\t\t\t    \"geo_country_name\":geoResponse.country.name,\n",
        "\t\t\t\t    \"geo_subdivisions\":geoResponse.subdivisions.most_specific.name, \n",
        "\t\t\t\t    \"geo_city_name\":geoResponse.city.name,\n",
        "\t\t\t\t    \"geo_lat\":geoResponse.location.latitude,\n",
        "\t\t\t\t    \"geo_lon\":geoResponse.location.longitude,\n",
        "\t\t\t\t    \"geo_iso_code\":geoResponse.country.iso_code,\n",
        "\t\t\t\t    \"geo_postal_code\":geoResponse.postal.code}\n",
        "\t\n",
        "\tgeoIPList.append(geoData)\n",
        "\t\n",
        "\treturn geoIPList\n",
        "\n",
        "\n",
        "def getIndicators(session, ip, otxList):\n",
        "    headers = {\"X-OTX-API-KEY\": \"GET_API_KEY_FROM_ALIENVAULT_OTX\",\n",
        "                   \"Accept\": \"application/json\"}\n",
        "    \n",
        "    otx_url = \"https://otx.alienvault.com/api/v1/indicator/IPv4/%s/malware\" % ip\n",
        "    \n",
        "    try:\n",
        "        response = session.get(otx_url, headers=headers, timeout=3)\n",
        "    \n",
        "        public_ip = {\"public_ip\": ip}\n",
        "        new_json = {}\n",
        "        data_len = len(response.json()[\"data\"])\n",
        "        if data_len > 0:\n",
        "            new_json = response.json()[\"data\"][0]\n",
        "            new_json.update(public_ip)\n",
        "        else:\n",
        "            new_json = {\"datetime_int\": \"\", \"hash\": \"\", \"detections\": \"\", \"date\": \"\"}\n",
        "            new_json.update(public_ip)\n",
        "    \n",
        "    except Exception as e:\n",
        "        public_ip = {\"public_ip\": ip}\n",
        "        new_json = {\"datetime_int\": \"\", \"hash\": \"\", \"detections\": \"\", \"date\": \"\"}\n",
        "        new_json.update(public_ip)\n",
        "        pass\n",
        "    \n",
        "    otxList.append(new_json)\n",
        "    \n",
        "    return otxList\n",
        "\n",
        "\n",
        "def checkEVA(session, src_email, evaList):\n",
        "    url = \"https://api.eva.pingutil.com/email\"\n",
        "    params = { \"email\": src_email }\n",
        "\n",
        "    response = session.get(url, params=params)\n",
        "\n",
        "    evaList.append(response.json()[\"data\"])\n",
        "\n",
        "    return evaList\n",
        "\n",
        "\n",
        "def getOfficeNearestDistance(geo_lat, geo_lon, country_id, iso_country_id, dfOffices):\n",
        "    lstDistance = []\n",
        "    distance = 0\n",
        "\n",
        "    # Filter only Offices available within the connection's source country\n",
        "    dfOffices = dfOffices[(dfOffices.suc_country_id == country_id)]\n",
        "    \n",
        "    if country_id == iso_country_id:\n",
        "        for index, row in dfOffices.iterrows():\n",
        "\n",
        "            #try:\n",
        "            suc_city = row[\"suc_city\"] \n",
        "            suc_full_name = row[\"suc_full_name\"]\n",
        "            suc_full_address = row[\"suc_full_address\"]\n",
        "           \n",
        "            geo_lat_lon = (float(geo_lat), float(geo_lon))\n",
        "\n",
        "            if \",\" in str(row[\"suc_latitude\"]): row[\"suc_latitude\"] = str(row[\"suc_latitude\"]).replace(\",\",\".\")\n",
        "            if \",\" in str(row[\"suc_longitude\"]): row[\"suc_longitude\"] = str(row[\"suc_longitude\"]).replace(\",\",\".\")\n",
        "\n",
        "            suc_latitude = float(row[\"suc_latitude\"])\n",
        "            suc_longitude = float(row[\"suc_longitude\"])\n",
        "            suc_lat_lon = (suc_latitude, suc_longitude)\n",
        "\n",
        "            distance = round(hs.haversine(geo_lat_lon, suc_lat_lon), 2)\n",
        "\n",
        "            lstDistance.append(distance)\n",
        "\n",
        "        if not lstDistance:\n",
        "            lstDistance.append(distance)\n",
        "\n",
        "    else:\n",
        "        lstDistance.append(distance)\n",
        "\n",
        "    nearest_suc_distance = min(lstDistance, key=lambda suc_data:distance)\n",
        "\n",
        "    return nearest_suc_distance"
      ],
      "metadata": {
        "id": "yn_jtQDEAMND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Initial DataFrames from Sources"
      ],
      "metadata": {
        "id": "z4uOgJ32HTD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Site connections data from CSV\n",
        "dfConnData = pd.read_csv(r\"/content/drive/MyDrive/SANS_DFIR_2022/connections.csv\")\n",
        "# Just get 10% of the rows (randomly)\n",
        "dfConnData = dfConnData.sample(frac = 0.005)\n",
        "\n",
        "# Getting Site connections data from DB\n",
        "#dfConnData = getConnData(pgUser, pgPass, pgHost, pgDB, pgPort)\n",
        "\n",
        "dfConnData"
      ],
      "metadata": {
        "id": "99cu9GU3Cy1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Site offices data\n",
        "dfOffices = pd.read_csv(r\"/content/drive/MyDrive/SANS_DFIR_2022/offices.csv\")\n",
        "dfOffices"
      ],
      "metadata": {
        "id": "aXuIvW6CFmRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Countries ISO codes\n",
        "dfISOCountries = pd.read_csv(r\"/content/drive/MyDrive/SANS_DFIR_2022/iso3countries_v2.csv\")\n",
        "\n",
        "# Select columns iso_country_id, iso2 for later joining\n",
        "dfISOCountries = dfISOCountries[[\"iso_country_id\", \"iso2\"]]\n",
        "dfISOCountries"
      ],
      "metadata": {
        "id": "qVjgLv1tLyuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtain UNIQUE IPs and Email addresses for processing"
      ],
      "metadata": {
        "id": "5h_ZCsh9dudv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtanin IP list from dataframe\n",
        "lstIP = dfConnData['public_ip'].tolist()\n",
        "# Removing duplicate IPs\n",
        "lstIP = set(lstIP)"
      ],
      "metadata": {
        "id": "8mWTfEQAHgkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtanin Email list from dataframe\n",
        "lstMails = dfConnData['email'].tolist()\n",
        "# Removing duplicate Emails\n",
        "lstMails = set(lstMails)"
      ],
      "metadata": {
        "id": "eJQyH0N_aUao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtain and process Geo Data"
      ],
      "metadata": {
        "id": "WEfUzmIwdrJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Init Geoloc data list\n",
        "geoIPList = []\n",
        "\n",
        "# Get Geolocation data for each IP\n",
        "[ getGeoData(ip, geoIPList) for ip in lstIP ]\n",
        "\n",
        "# Generate Dataframe with the Geoloc data\n",
        "dfGeoIPData = pd.DataFrame(geoIPList)\n",
        "dfGeoIPData"
      ],
      "metadata": {
        "id": "QZl_To58K-bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# START API REQUESTS CALLS"
      ],
      "metadata": {
        "id": "d9j1yMTDtiya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain and process Threat-intel data from AlienVault OTX"
      ],
      "metadata": {
        "id": "aXCTcOAlYt_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "otxList = []\n",
        "\n",
        "# Get AlienVault OTX data for each IP\n",
        "sessionOTX = req.session()\n",
        "[ getIndicators(sessionOTX, ip, otxList) for ip in lstIP ]\n",
        "\n",
        "# Generate Dataframe with the AlienVault OTX data\n",
        "dfOTX = pd.DataFrame(otxList, columns=[\"hash\", \"detections\", \"date\", \"public_ip\"])\n",
        "dfOTX"
      ],
      "metadata": {
        "id": "tHv8hJYNTduv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain and process Email address data from EVA"
      ],
      "metadata": {
        "id": "SLKN-8nOdYfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Traditional way (session requests)\n",
        "evaList = []\n",
        "\n",
        "# Get EVA data for each IP\n",
        "sessionEVA = req.session()\n",
        "[ checkEVA(sessionEVA, em, evaList) for em in lstMails ]\n",
        "\n",
        "# Generate Dataframe with EVA data\n",
        "dfEVA = pd.DataFrame(evaList, columns=[\"email_address\",\"domain\",\"valid_syntax\",\n",
        "                                       \"disposable\",\"webmail\",\"deliverable\",\n",
        "                                       \"catch_all\",\"gibberish\",\"spam\"])\n",
        "dfEVA"
      ],
      "metadata": {
        "id": "YzJ6N-yfaBtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Connections DF with GeoLocation DF"
      ],
      "metadata": {
        "id": "63Yp6Oe_YLHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Geolocation data to Connections dataframe\n",
        "dfFullData = pd.merge(dfConnData, dfGeoIPData, left_on='public_ip', right_on='geo_ip')\n",
        "\n",
        "# Merging and adding useful ISO data to Geo dataframe for later use.\n",
        "# \"country_id\" (ID entered by the user) VS. \"iso_country_id\" (actual ID based on IP Geo location)\n",
        "dfFullData = pd.merge(dfFullData, dfISOCountries, left_on=\"geo_iso_code\", right_on=\"iso2\")\n",
        "dfFullData"
      ],
      "metadata": {
        "id": "g5uknSDsYKea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Connections DF with AlienVault DF"
      ],
      "metadata": {
        "id": "e8sZh0MJRcAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding AlientVault OTX data to Connections dataframe\n",
        "dfFullData = pd.merge(dfFullData, dfOTX, how=\"left\", on=\"public_ip\")\n",
        "dfFullData"
      ],
      "metadata": {
        "id": "pDL7GDkWRNXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Connections DF with EVA DF"
      ],
      "metadata": {
        "id": "BtSGYip31Kha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding EVA data to Connections dataframe\n",
        "dfFullData = pd.merge(dfFullData, dfEVA, left_on=\"email\", right_on=\"email_address\")\n",
        "dfFullData"
      ],
      "metadata": {
        "id": "YynwfVj7SKET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nearest Office"
      ],
      "metadata": {
        "id": "ml0Mv_vd2scp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Nearest Office distance from IP GeoLocation to Connections dataFrame\n",
        "dfFullData['nearest_office_data'] = dfFullData.apply(\n",
        "    lambda row: getOfficeNearestDistance(row['geo_lat'], row['geo_lon'], \n",
        "                                         row['country_id'], row['iso_country_id'], \n",
        "                                         dfOffices), axis=1)\n",
        "dfFullData"
      ],
      "metadata": {
        "id": "HJxCJ11gVgIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filtering Results (optional)"
      ],
      "metadata": {
        "id": "LuNWTprpPbLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter DF\n",
        "dfFullDataFiltered = dfFullData.query(\"hash != ''\")\n",
        "dfFullData\n",
        "\n",
        "# Filtering using variables\n",
        "country_to_search = 'Turkey'\n",
        "dfFullDataFilteredByCountry = dfFullDataFiltered.query(\"geo_country_name == @country_to_search\")\n",
        "dfFullDataFilteredByCountry"
      ],
      "metadata": {
        "id": "GSnuklPOPang"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Results"
      ],
      "metadata": {
        "id": "W9XfDQCHQDAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install GeoPandas libraries\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "8xrLctyuQAHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import Point\n",
        "import geopandas as gpd\n",
        "from geopandas import GeoDataFrame\n",
        "\n",
        "geometry = [Point(xy) for xy in zip(dfFullData['geo_lon'], dfFullData['geo_lat'])]\n",
        "gdf = GeoDataFrame(dfFullData, geometry=geometry)   \n",
        "\n",
        "#World Map (Cities)\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "gdf.plot(ax=world.plot(figsize=(15, 7), color=\"grey\"), marker='o', color='red', markersize=10);"
      ],
      "metadata": {
        "id": "I15V38ZR_0h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Countries Chart\n",
        "dfFullData.loc[(dfFullData.geo_country_name == 'United States of America'),'geo_country_name']='USA'\n",
        "dfFullData.groupby(['geo_country_name']).count()['creation_date'].plot(title=\"Requests by Country\", \n",
        "                                                                       kind=\"barh\", \n",
        "                                                                       figsize=(11,5), \n",
        "                                                                       colormap='Paired')"
      ],
      "metadata": {
        "id": "MlqurYx-A4wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Send to Google Sheets"
      ],
      "metadata": {
        "id": "3xqU1VLhnjiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install pygsheets to interact with Google Sheets\n",
        "!pip install pygsheets\n",
        "!pip install --upgrade -q pygsheets"
      ],
      "metadata": {
        "id": "FdLg8NfL6wcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate from Colab  \n",
        "import google.auth\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Use current credentials to connect to Google Sheets\n",
        "import pygsheets\n",
        "credentials, _ = google.auth.default()\n",
        "gc = pygsheets.client.Client(credentials)"
      ],
      "metadata": {
        "id": "33PmFiOzATLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sh = gc.open('SANSDFIR2022')\n",
        "wks = sh.worksheet_by_title('Report')\n",
        "wks.clear()\n",
        "wks.set_dataframe(dfFullData, (1, 1))"
      ],
      "metadata": {
        "id": "UYMP8a_B68gE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}